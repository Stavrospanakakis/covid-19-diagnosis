\documentclass{article}

\usepackage{graphicx}
\usepackage{float}
\usepackage{multicol}

\title{Covid-19 study with Neural Networks}
\author{Stavros Panakakis, Sophia Tsivoula}

\begin{document}
	\maketitle
	

\section{Introduction}
Coronavirus (COVID-19) is a new virus that has evolved into a pandemic on March 2020. Specifically, the first cases of Coronavirus (COVID-19) were detected in the city of Wuhan, China in December 2019 in seafood wholesale market. A number of attends initially diagnosed with a form of pneumonia where later discovered through samples of sufferers, that originates from an unknown (till then) beta-coronavirus virus.\cite{firstcases} 

The most common symptoms of the virus today are fever, cough, fatigue, expectoration and shortness of breath. More rarely, sufferers experience headaches or dizziness, diarrhea, nausea and vomiting.\cite{symptoms1}. 

\section{Impact of Covid-19}

\subsection{Cases}

\begin{figure}[H]
\includegraphics[width=\linewidth]{cases/worldwide/plot.png}
  \caption{Covid-19 worldwide cases.}
  \label{fig:worldwidecases}
\end{figure}

\begin{figure}[H]
\includegraphics[width=\linewidth]{cases/greece/plot.png}
  \caption{Covid-19 Cases in Greece.}
  \label{fig:greececases}
\end{figure}

\subsection{Cost}

\section{Need for analytics}

\section{Review}

\textbf{Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks}\cite{firstreview}

They used 10 Convolutional Neural Networks. The network with the best accuracy was ResNet-101\cite{resnet} and the accuracy was 99.51 percent.
The number of COVID-19 patients is 108 (48 female and 60 male) and for non-COVID-19 is 86 (35 female and 51 male). The age of COVID-19 is 50.22 +- 10.85
and of non-COVID-19 is 61.45 +- 15.04. The images converted to grayscale and reviewed by an experianced radiologist.The input layer of the CNNs were replaced
with a new one. The dimension of the last fully connected layer of all networks was set to the number of the classes. All the networks were trained with SGDM 
optimizer, learning rate=0.01 and validation frequency = 5. In each epoch the dataset shuffled. The dataset divided to 80 percent train and 20 percent validation. 

\begin{table}[H]
  \begin{center}
    \caption{Results of 10 CNN}
    \label{tab:table1}
    \begin{tabular}{||c c c c c ||}
      \hline 
      \textbf{Reference} & \textbf{Network} & \textbf{Depth} & \textbf{Parameters} & \textbf{Accuracy}\\ 
      \hline
      \cite{alexnet} & AlexNet & 8 & 61 & 78.92  \\ % <--
      \hline
      \cite{vgg} & VGG-16 & 16 & 138 & 83.33  \\ % <--
	  \hline
      \cite{vgg} & VGG-19 & 19 & 144 & 85.29  \\ % <--
      \hline 
      \cite{squeezenet} & SqueezeNet & 18 & 1.24 & 82.84  \\ % <--
      \hline
      \cite{googlenet} & GoogleNet & 22 & 7 & 85.29  \\ % <--
      \hline
      \cite{mobilenet} & MobileNet-V2 & 53 & 3.5 & 92.16  \\ % <--
      \hline
      \cite{resnet} & ResNet-18 & 18 & 11.7 & 91.67  \\ % <--
      \hline
      \cite{resnet} & ResNet-50 & 50 & 25.6 & 94.12  \\ % <--
      \hline
      \cite{resnet} & ResNet-101 & 101 & 44.6 & 99.51  \\ % <--
      \hline
      \cite{xception} & Xception & 71 & 22.9 & 99.02  \\ % <--
      \hline
    \end{tabular}
  \end{center}
\end{table}

\textbf{Automated detection of COVID-19 cases using deep neural networks with X-ray images}\cite{secondreview}

The network they used is DarkCovidNet which is based on Darknet-19\cite{darknet}as a starting point. The dataset that used is "A COVID-19 X-ray image databse" which developed by Cohen JP\cite{dataset1secondreview}. There are not complete metadata at the dataset. The patients that have COVID-19 in the dataset are 125(43 female and 82 male). The average age of 26 of them is 55 years. Another dataset is ChestX-ray8 database which developed by Wang et al.\cite{dataset2secondreview} and was used for normal and pneumonia images. It is used optimizer=Adam, loss function=cross entropy and learning rate=3e-3.The datasets divided to 80 percent train and 20 percent validation. The model outputs evaluated by an expert radiologist. They did it with 2 ways. With binary(covid vs healthy) as well as multi classes (covid vs pneumonia vs health). The accuracy for binary is 98.08 and for multi classes 87.02.

\begin{figure}[H]
\includegraphics[width=\linewidth]{assets/architecture-of-the-darkcovidnet-ozturk-tulin-et-al.png}
  \caption{Architecture of the DarkCovidNet}
  \label{fig:paper3architecture}
\end{figure}

\textbf{Computer-aided detection of COVID-19 from X-ray images using multi-CNN and Bayesnet classifier}\cite{thirdreview}

This paper has a combination of features extracted from multi-CNN and used the Bayesnet classifier for the prediction of COVID-19. The networks that used were Squeezenet\cite{squeezenet}, Darknet-53\cite{darknetpaper3}, MobilenetV2\cite{mobilenet}, Xception\cite{xception}, Shufflenet\cite{shufflenet} in order to produce a feature matrix of dimension 950x5000. Each network was pre-trained using Imagenet\cite{imagenet}. The feature matrix is passed to the Bayesnet classifier which classifies the images into COVID-19 and non-COVID categories. The first dataset is a combination of a dataset created by Cohen et al\cite{dataset1secondreview} and a dataset by Kaggle\cite{dataset1.2thirdreview} and has 453 COVID-19 images and 497 non-COVID images(bacterial, varial pneumonia) and had 91.16 percent accuracy. The second dataset\cite{dataset2thirdreview} had 71 COVID-19 images and 7 non-COVID images and had 97.44 percent accuracy. 

\begin{figure}[H]
\includegraphics[width=\linewidth]{assets/architecture-of-the-proposed-method-abraham-bejoy-et-al.png}
  \caption{Architecture of the proposed method}
  \label{fig:paper3architecture}
\end{figure}


\section{Results}

\section{Research}

\section{Results}

\section{Future Work}

\begin{thebibliography}{9}
\bibitem{firstcases} 
Zhu, Na, et al. 
\textit{A novel coronavirus from patients with pneumonia in China, 2019.}. 
New England Journal of Medicine (2020).

\bibitem{symptoms1}
Li, Long‐quan, et al.
\textit{COVID‐19 patients' clinical characteristics, discharge rate, and fatality rate of meta‐analysis.}
Journal of medical virology 92.6 (2020): 577-583.

\bibitem{symptoms2} 
Huang, Chaolin, et al. 
\textit{Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China.}.
The lancet 395.10223 (2020): 497-506.

\bibitem{firstreview}
Ardakani, Ali Abbasian, et al. 
\textit{Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks.}.
Computers in Biology and Medicine (2020): 103795.

\bibitem{alexnet}
Krizhevsky Ilya Sutskever, et al. 
\textit{Imagenet classification with deep convolutional neural networks.}. Advances in neural information processing systems. 2012.

\bibitem{vgg}
Simonyan, Karen, et al. 
\textit {Very deep convolutional networks for large-scale image recognition.}. arXiv preprint arXiv:1409.1556 (2014).

\bibitem{squeezenet}
Iandola, Forrest N., et al. 
\textit {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size.}. 
arXiv preprint arXiv:1602.07360 (2016).

\bibitem{googlenet}
C. Szegedy et al. 
\textit{Going deeper with convolutions}
2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, 2015, pp. 1-9, doi: 10.1109/CVPR.2015.7298594.

\bibitem{mobilenet}
M. Sandler, A. Howard et al. 
\textit{MobileNetV2: Inverted Residuals and Linear Bottlenecks}
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, 2018, pp. 4510-4520, doi: 10.1109/CVPR.2018.00474.

\bibitem{resnet}
K. He, X. Zhang, et al. 
\textit{Deep Residual Learning for Image Recognition.}. 
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, 2016, pp. 770-778, doi: 10.1109/CVPR.2016.90.

\bibitem{xception}
Chollet, François. 
\textit{Xception: Deep learning with depthwise separable convolutions.}. Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.

\bibitem{secondreview}
Ozturk, Tulin, et al. 
\textit{Automated detection of COVID-19 cases using deep neural networks with X-ray images}. 
Computers in Biology and Medicine (2020): 103792.

\bibitem{darknet}
Redmon, Joseph et al.
\textit{YOLO9000: better, faster, stronger.}.
Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.

\bibitem{dataset1secondreview}
J.P. Cohen
\textit{COVID-19 Image Data Collection. 2020.}
https://github.com/ieee8023/COVID-chestxray-dataset.

\bibitem{dataset2secondreview}
X. Wang et al. 
\textit{Chestx-ray8: hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases}
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2097–2106.

\bibitem{thirdreview}
Abraham, Bejoy et al. 
\textit{Computer-aided detection of COVID-19 from X-ray images using multi-CNN and Bayesnet classifier.}.
Biocybernetics and biomedical engineering 40.4 (2020): 1436-1445.

\bibitem{dataset1.2thirdreview}
Kermany, et al.
\textit{Identifying medical diagnoses and treatable diseases by image-based deep learning.}.
Cell 172.5 (2018): 1122-1131.

\bibitem{dataset2thirdreview}
Dadario AMV. Covid-19 X rays; 2020.
\textit{http://dx.doi.org/10.34740/KAGGLE/DSV/101946}. 
Available from:https://www.kaggle.com/dsv/1019469. 

\bibitem{imagenet}
Deng J et al.
\textit{Imagenet: alarge-scale hierarchical image database.}.
2009 IEEEConference on Computer Vision and Pattern Recognition.IEEE; 2009. p. 248–55.

\bibitem{shufflenet}
Zhang X et al.
\textit{Shufflenet: an extremelyefficient convolutional neural network for mobile devices.}.
Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition; 2018. p. 6848–56.

\bibitem{darknetpaper3}
Redmon J et al. 
\textit{Yolov3: an incremental improvement.}.
2018, arXiv preprint arXiv:1804.02767
\end{thebibliography}
\end{document}