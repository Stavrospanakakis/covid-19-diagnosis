\documentclass{article}

\usepackage{graphicx}

\title{Covid-19 study with Neural Networks}
\author{Stavros Panakakis, Sophia Tsivoula}

\begin{document}
	\maketitle

\section{Introduction}
The first novel Coronavirus (COVID-19) disease cases confirmed at a seafood wholesale market in Wuhan, China in December 2019 with pneumonia of 
unknown cause.\cite{firstcases} The most common symptoms are fever, cough, myalgia and fatigue while the less common ones are sputum production, 
headache, haemoptysis and diarrhoea.\cite{symptoms} 

\section{Impact of Covid-19}

\subsection{Cases}

\begin{figure}[h!]
\includegraphics[width=\linewidth]{cases/worldwide/plot.png}
  \caption{Covid-19 worldwide cases.}
  \label{fig:worldwidecases}
\end{figure}

\begin{figure}[h!]
\includegraphics[width=\linewidth]{cases/greece/plot.png}
  \caption{Covid-19 Cases in Greece.}
  \label{fig:greececases}
\end{figure}

\subsection{Cost}

\section{Need for analytics}

\section{Review}

\textbf{Results of 10 CNN}\cite{firstreview}

They used 10 Convolutional Neural Networks. The network with the best accuracy was ResNet-101\cite{resnet} and the accuracy was 99.51 percent.
The number of COVID-19 patients is 108 (48 female and 60 male) and for non-COVID-19 is 86 (35 female and 51 male). The age of COVID-19 is 50.22 +- 10.85
and of non-COVID-19 is 61.45 +- 15.04. The images converted to grayscale and reviewed by an experianced radiologist.The input layer of the CNNs were replaced
with a new one. The dimension of the last fully connected layer of all networks was set to the number of the classes. All the networks were trained with SGDM 
optimizer, learning rate=0.01 and validation frequency = 5. In each epoch the dataset shuffled. The dataset divided to 80 percent train and 20 percent validation. 

\begin{table}[h!]
  \begin{center}
    \caption{Results of 10 CNN}
    \label{tab:table1}
    \begin{tabular}{||c c c c c ||}
      \hline 
      \textbf{Reference} & \textbf{Network} & \textbf{Depth} & \textbf{Parameters} & \textbf{Accuracy}\\ 
      \hline
      \cite{alexnet} & AlexNet & 8 & 61 & 78.92  \\ % <--
      \hline
      \cite{vgg} & VGG-16 & 16 & 138 & 83.33  \\ % <--
	  \hline
      \cite{vgg} & VGG-19 & 19 & 144 & 85.29  \\ % <--
      \hline 
      \cite{squeezenet} & SqueezeNet & 18 & 1.24 & 82.84  \\ % <--
      \hline
      \cite{googlenet} & GoogleNet & 22 & 7 & 85.29  \\ % <--
      \hline
      \cite{mobilenet} & MobileNet-V2 & 53 & 3.5 & 92.16  \\ % <--
      \hline
      \cite{resnet} & ResNet-18 & 18 & 11.7 & 91.67  \\ % <--
      \hline
      \cite{resnet} & ResNet-50 & 50 & 25.6 & 94.12  \\ % <--
      \hline
      \cite{resnet} & ResNet-101 & 101 & 44.6 & 99.51  \\ % <--
      \hline
      \cite{xception} & Xception & 71 & 22.9 & 99.02  \\ % <--
      \hline
    \end{tabular}
  \end{center}
\end{table}

\section{Results}

\section{Research}

\section{Results}

\section{Future Work}

\begin{thebibliography}{9}
\bibitem{firstcases} 
Zhu, Na, et al. 
\textit{A novel coronavirus from patients with pneumonia in China, 2019.}. 
New England Journal of Medicine (2020).

\bibitem{symptoms} 
Huang, Chaolin, et al. 
\textit{Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China.}.
The lancet 395.10223 (2020): 497-506.

\bibitem{firstreview}
Ardakani, Ali Abbasian, et al. 
\textit{Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks.}.
Computers in Biology and Medicine (2020): 103795.

\bibitem{alexnet}
Krizhevsky Ilya Sutskever, et al. 
\textit{Imagenet classification with deep convolutional neural networks.}. Advances in neural information processing systems. 2012.

\bibitem{vgg}
Simonyan, Karen, et al. 
\textit {Very deep convolutional networks for large-scale image recognition.}. arXiv preprint arXiv:1409.1556 (2014).

\bibitem{squeezenet}
Iandola, Forrest N., et al. 
\textit {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size.}. 
arXiv preprint arXiv:1602.07360 (2016).

\bibitem{googlenet}
C. Szegedy et al. 
\textit{Going deeper with convolutions}
2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, 2015, pp. 1-9, doi: 10.1109/CVPR.2015.7298594.

\bibitem{mobilenet}
M. Sandler, A. Howard et al. 
\textit{MobileNetV2: Inverted Residuals and Linear Bottlenecks}
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, 2018, pp. 4510-4520, doi: 10.1109/CVPR.2018.00474.

\bibitem{resnet}
K. He, X. Zhang, et al. 
\textit{Deep Residual Learning for Image Recognition.}. 
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, 2016, pp. 770-778, doi: 10.1109/CVPR.2016.90.

\bibitem{xception}
Chollet, FranÃ§ois. 
\textit{Xception: Deep learning with depthwise separable convolutions.}. Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.

\end{thebibliography}

\end{document}