\documentclass{article}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{float}
	\usepackage{multicol}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }


\title{Covid-19 study with Neural Networks}
\author{Stavros Panakakis, Sophia Tsivoula}

\begin{document}
	\maketitle

\begin{abstract}
There will be the abstract
\end{abstract}

\section{Description}
Coronavirus (COVID-19) is a newly infectious disease that has evolved into a pandemic in March 2020. Specifically, the first cases of Coronavirus (COVID-19) were detected in the city of Wuhan, China in December 2019 in a seafood wholesale market. A number of patients initially diagnosed with a form of pneumonia, that later discovered through samples of sufferers, that originates from an unknown, till then, beta-coronavirus virus \cite{firstcases}.

The most common symptoms of the virus today are fever, cough, fatigue, expectoration and shortness of breath. More rarely, sufferers experience headaches or dizziness, diarrhea, nausea and vomiting \cite{symptoms1}. Examining the samples from the sufferers, it was observed that some social groups are more likely to get infected and experience severe respiratory problems originated from the virus  [Figure: \ref{fig:CovidCasesChina}] \cite{patients}.

\begin{figure}[H]
\includegraphics[width=\linewidth]{assets/cases-in-china.png}
  \caption{Impact of cardiovascular metabolic diseases on COVID-19 in China}
  \label{fig:CovidCasesChina}
\end{figure}

Coronavirus is a RNA positive-strand virus, thus has higher mutation rates than DNA virus. This is the reason why  Coronaviruses are easy to adopt in different environments in order to survive and reproduce. COVID-19 is life threatening to humans because the human body has not developed immunity to the virus. Patients' data is relatively encouraging since 85\% of COVID-19 patients suffered from mild infection, 10\% from severe and only 5\% of patients suffered from critical infection. Most critical COVID-19 cases are elderly people, people suffering from other diseases and individuals who have a weak immune system \cite{medicalCOVID}. This means that  COVID-19 is able to spread and reproduce easier and faster on the respiratory system of the patients and cause COVID-19 pneumonia [Figure: \ref{fig:CovidCasesChina}].
\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{assets/covid-vs-pneumonia-vs-normal.png}
  \caption{Healthy person vs Normal Pneumonia vs COVID-19 Pneumonia}
  \label{fig:xraycomparison}
\end{figure}



\section{Impact of Covid-19}

\subsection{Cases}

\begin{figure}[H]
\begin{center}
\includegraphics{cases/worldwide/plot.png}
  \caption{Covid-19 worldwide cases.}
  \label{fig:worldwidecases}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics{cases/greece/plot.png}
  \caption{Covid-19 Cases in Greece.}
  \label{fig:greececases}
  \end{center}
\end{figure}

\subsection{Cost}

\section{Need for analytics}
Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages.

---------------------------------------------

Fast diagnostic methods can control and prevent the spread of pandemic diseases like coronavirus disease 2019
(COVID-19) and assist physicians to better manage patients in high workload conditions. Although a laboratory

test is the current routine diagnostic tool, it is time-consuming, imposing a high cost and requiring a well-
equipped laboratory for analysis. Computed tomography (CT) has thus far become a fast method to diagnose

patients with COVID-19. However, the performance of radiologists in diagnosis of COVID-19 was moderate.
Accordingly, additional investigations are needed to improve the performance in diagnosing COVID-19. In this
study is suggested a rapid and valid method for COVID-19 diagnosis using an artificial intelligence technique
based. 1020

-----------------------------------------------

Fast diagnostic methods can control and prevent the spread of pandemic diseases like coronavirus disease 2019
(COVID-19) and assist physicians to better manage patients in high workload conditions. Although a laboratory

test is the current routine diagnostic tool, it is time-consuming, imposing a high cost and requiring a well-
equipped laboratory for analysis. Computed tomography (CT) has thus far become a fast method to diagnose

patients with COVID-19. However, the performance of radiologists in diagnosis of COVID-19 was moderate.
Accordingly, additional investigations are needed to improve the performance in diagnosing COVID-19. In this
study is suggested a rapid and valid method for COVID-19 diagnosis using an artificial intelligence technique
based. 1020

----------------------------------------------


\section{Review}
\textbf{Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks}\cite {firstreview}  
\\
\\
The first study focuses on the improvement of COVID-19 diagnosis process  and proposes artificial intelligent techniques for reliable and faster results from previous methods, such as computed tomography (CT). More specifically the study uses ten Convolutional Neural Networks (CNN) and explains the accuracy on each of them [Table: \ref{tab:table1}]. The network ResNet-101 \cite{resnet} achieved 99.51\% accuracy, the best one described in this study. In the study participated 108 patients (48 female and 60 male) positive with COVID-19 and 86 (35 female and 51 male)  non-COVID-19 patients. The age of COVID-19 positive is 50.22 $\pm$ 10.85 and of non-COVID-19 is 61.45 $\pm$ 15.04. In order to create the CNN, the computed tomography images were converted to grayscale and reviewed by an experienced radiologist. In order to make the CNN more efficient, for every different network used in the study, the input layer was replaced with a new one based on the size of COVID-19 infection patches and the dimensions of the last fully connected layer were set to the number of classes. The optimizer used was SGDM, the values of learning rate equals 0.01 and validation frequency was set to 5. The dataset is divided to 80\% train data and 20\% validation data. In each epoch the dataset was shaffled and if the training process stayed the same, the training process stopped.

\begin{table}[H]
  \begin{center}
    \caption{Results of 10 CNN}
    \label{tab:table1}
    \begin{tabular}{||c c c c c ||}
      \hline 
      \textbf{Reference} & \textbf{Network} & \textbf{Depth} & \textbf{Parameters} & \textbf{Accuracy}\\ 
      \hline
      \cite{alexnet} & AlexNet & 8 & 61 & 78.92  \\ % <--
      \hline
      \cite{vgg} & VGG-16 & 16 & 138 & 83.33  \\ % <--
	  \hline
      \cite{vgg} & VGG-19 & 19 & 144 & 85.29  \\ % <--
      \hline 
      \cite{squeezenet} & SqueezeNet & 18 & 1.24 & 82.84  \\ % <--
      \hline
      \cite{googlenet} & GoogleNet & 22 & 7 & 85.29  \\ % <--
      \hline
      \cite{mobilenet} & MobileNet-V2 & 53 & 3.5 & 92.16  \\ % <--
      \hline
      \cite{resnet} & ResNet-18 & 18 & 11.7 & 91.67  \\ % <--
      \hline
      \cite{resnet} & ResNet-50 & 50 & 25.6 & 94.12  \\ % <--
      \hline
      \cite{resnet} & ResNet-101 & 101 & 44.6 & 99.51  \\ % <--
      \hline
      \cite{xception} & Xception & 71 & 22.9 & 99.02  \\ % <--
      \hline
    \end{tabular}
  \end{center}
\end{table}

\textbf{Automated detection of COVID-19 cases using deep neural networks with X-ray images}\cite{secondreview}
\\ 
\\
The second paper called “Automated detection of COVID-19 cases using deep neural networks with X-ray images” trained a CNN in order to detect if a person is healthy or suffers from COVID-19 or normal pneumonia. On the paper were used two different datasets. The first one was called "A COVID-19 X-ray image database" which was developed by Cohen JP \cite{dataset1secondreview}. The dataset does not contain enough metadata referring to patients nevertheless, there were 125 positive with COVID-19 patients from whom 43 were female and 83 were male. Another information is that out of 26 patients the average age of them was 55 years. The second dataset that was used was the “ChestX-ray8 database” which was developed by Wang et al. \cite{dataset2secondreview}. This dataset contained X-ray images with healthy patients and patients with normal pneumonia however, it does not provide any metadata for the patients. The network had two different variants. The first one was able to detect whether or not the patients suffer from COVID-19. In order to train the network, from the second dataset, only the X-rays with healthy patients  were used, to help the network to classify a patient as healthy or COVID-19 positive. In the second one, the network was able to detect if a patient is healthy or suffers from COVID-19 or suffers from normal pneumonia. For this network, all two datasets were combined in order to get all three different results. The network used was the “DarkCovidNet” which is based on “Darknet-19” \cite{darknet}, the optimizer was Adam, cross entropy was used as a loss function and the learning rate was 3e-3. Finally, the accuracy for binary classification was 98.08 percent and for categorical 87.02 percent.


\begin{figure}[H]
\includegraphics[width=\linewidth]{assets/architecture-of-the-darkcovidnet-ozturk-tulin-et-al.png}
  \caption{Architecture of the DarkCovidNet}
  \label{fig:paper3architecture}
\end{figure}

\textbf{Computer-aided detection of COVID-19 from X-ray images using multi-CNN and Bayesnet classifier}\cite{thirdreview}

This paper has a combination of features extracted from multi-CNN and used the Bayesnet classifier for the prediction of COVID-19. The networks that used were Squeezenet\cite{squeezenet}, Darknet-53\cite{darknetpaper3}, MobilenetV2\cite{mobilenet}, Xception\cite{xception}, Shufflenet\cite{shufflenet} in order to produce a feature matrix of dimension 950x5000. Each network was pre-trained using Imagenet\cite{imagenet}. The feature matrix is passed to the Bayesnet classifier which classifies the images into COVID-19 and non-COVID categories. The first dataset is a combination of a dataset created by Cohen et al\cite{dataset1secondreview} and a dataset by Kaggle\cite{dataset1.2thirdreview} and has 453 COVID-19 images and 497 non-COVID images(bacterial, varial pneumonia) and had 91.16 percent accuracy. The second dataset\cite{dataset2thirdreview} had 71 COVID-19 images and 7 non-COVID images and had 97.44 percent accuracy. 

\begin{figure}[H]
\includegraphics[width=\linewidth]{assets/architecture-of-the-proposed-method-abraham-bejoy-et-al.png}
  \caption{Architecture of the proposed method}
  \label{fig:paper3architecture}
\end{figure}


\section{COVnet-101}

\subsection{ResNet-101}
\label{ResNet-101}
For this exercise, instead of just reviewing papers, we designed our custom neural network based on the ResNet-101\cite{resnet}. In order to explain the custom network, the  ResNet-101 should be presented. \par
    The ResNet was trained using ImageNet 2012 Dataset \cite{imagenet} and for its creation two models were trained. More specifically, these two models were a plain model and a residual model. \par
The plain network is inspired by the philosophy of VGG networks\cite{vgg}. The filters used in the convolutional layers were mostly 3x3, the network ends with global averages pooling layer and 1000 way fully-connected layer with softmax and the total number of weighted layers is 34.\par
The residual network is based on the plain network and the main difference is the addition of shortcut connections. These shortcuts function differently when the input and output have the same dimensions and when they do not. More accurately, when the input and output are not of the same dimensions, meaning that the dimensions are increasing, then there are two different scenarios: \par
1. The shortcut performs identity mapping with extra zero entries padded for increasing dimensions and this option does not add any extra parameters.\par
2. The projection shortcut is activated in order to match dimensions done by 1×1 convolutions.
When the input and output are the same dimensions then the identity shortcuts are used on the network. \par
    ResNet-101 was created with a residual network with 101 layers and 3-layer blocks in order to increase its accuracy.\par
The ResNet-101 was trained using the dataset named “imagenet 2012”. This dataset has 1000 classes, the models are trained at 1.28 million images and evaluated on 50k validation images. In order to increase the number of images the ResNet-101 creators used data augmentation techniques, more specifically scale augmentation and color augmentation. The images were cropped to 224×244 from random parts either from the original image or from horizontal flipped copies from the images and they applied standard color augmentation \cite{imagenet}. To make the neural network faster and stable through normalization they used batch normalization\cite{batchnormalization} right after each convolution and before activation. \par
 The optimizer was SGD with a mini-batch size of 256, the learning rate starts from 0.1 and is divided by 10 when the error plateaus and the models are trained for up to 60 × 104 iterations. They used a weight decay of 0.0001,  a momentum of 0.9 and dropout was not used\cite{dropout}.


\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.75]{assets/resnet-vs-vgg.png}
  \caption{VGG vs ResNet}
  \label{fig:vggvsresnet}
  \end{center}
\end{figure}

\subsection{COVnet-101 network}
COVnet-101, as mentioned in Section \ref{ResNet-101}, was based on ResNet-101. The method used is called “Transfer learning” meaning that ResNet-101 was used as a starting point to create COVnet-101. \par
The images used in COVnet-101  were re-sized to 128x128, then they were shuffled and normalized by dividing with 255. The input shape of the network is (5144, 128, 128 3), the batch size is 16, the optimizer is Adam and the learning rate is 0.01. \par
There are two different versions of the network. The first one is called “CovidvsNonCovid” and it detects COVID-19 on patients from X-ray images. This implies that non COVID-19 patients can be either healthy or suffer from other diseases instead of COVID-19. The second version is called  “CovidvsHealthyvsPneumonia” and it detects COVID-19 and/or pneumonia from X-ray images. This version of the network is an improved version of CovidvsNonCovid since it can detect if a patient is healthy or suffers from COVID-19 or suffers from pneumonia. In other words, the main difference of the two versions is that, the version called CovidvsHealthyvsPneumonia can detect more than one malady from an image. \par 
The dataset used for healthy and pneumonia chest X-ray images is from Kaggle created by Paul Mooney \cite{dataset1custom} and it contains 5,863 images. The datasets for COVID-19 detection were "A COVID-19 X-ray image database" which was developed by Cohen JP \cite{dataset1secondreview}, "COVID-19 Chest X-ray Dataset Initiative" \cite{datasetcustomcovid} as well as "Actualmed COVID-19 Chest X-ray Dataset Initiative" \cite{datasetcustomcovid}.  The total images are 6432 and the division to  trained / validation images percentage was 80\% / 20\%. 

\subsection{COVID vs Healthy vs Pneumonia}

In order to be able to detect if a patient suffers from COVID-19 or pneumonia or not, we created the "CovidvsHealthyvsPneumonia" network. For the classifications where used the Loss function which was used is Categorical Cross Entropy and the last’s layer function is Softmax because there were three different labels \par
The total parameters used on the network are 76,216,707, the trainable parameters are 33,558,531 and the non-trainable 42,658,176. The accuracy of the network was 91,5\%

\begin{table}[H]
  \begin{center}
    \caption{Covid vs healthy vs pneumonia}
    \label{tab:table3}
    \begin{tabular}{||c c c ||}
	  \hline
      \textbf{Layer (type)} & \textbf{Output Shape} & \textbf{Param}  \\  % <--
      \hline
      resnet101 (Functional) & (None, 4, 4, 2048) & 42658176 \\ % <--
      \hline
      flatten (Flatten) & (None, 32768) & 0 \\ % <--
      \hline
      dense (Dense) & (None, 1024) & 33555456 \\ % <--
      \hline 
      dropout (Dropout) & (None, 1024) & 0 \\ % <--
      \hline
      dense1 (Dense) & (None, 3) & 3075 \\ % <--
      \hline
    \end{tabular}
  \end{center}
\end{table}


\subsection{Covid vs NonCovid}

In order to be able to detect if a patient suffers from COVID-19 or not, we created the “CovidvsNonCovid” network. For the classifications where used the Loss function below is Binary Crossentropy and the Last’s layer function is Sigmoid because of the fact that they are two different labels. \par.
The total parameters used on the network are76,214,657, the trainable parameters are 33,556,481 and the non-trainable 42,658,176.The accuracy of the network was 97,4 \%

\begin{table}[H]
  \begin{center}
    \caption{Covid vs Non-Covid}
    \label{tab:table3}
    \begin{tabular}{||c c c ||}
	  \hline
      \textbf{Layer (type)} & \textbf{Output Shape} & \textbf{Param}  \\  % <--
      \hline
      resnet101 (Functional) & (None, 4, 4, 2048) & 42658176 \\ % <--
      \hline
      flatten (Flatten) & (None, 32768) & 0 \\ % <--
      \hline
      dense (Dense) & (None, 1024) & 33555456 \\ % <--
      \hline 
      dropout (Dropout) & (None, 1024) & 0 \\ % <--
      \hline
      dense1 (Dense) & (None, 1) & 1025 \\ % <--
      \hline
    \end{tabular}
  \end{center}
\end{table}

\section{Results}
The majority of papers focused on the creation of multiple networks. For instance, one for binary and one for categorical classification. However, the most accurate ones were these with binary classification ( COVID-19 vs Non-COVID-19 ). First of all, the first paper\cite{firstreview}, after training 10 Convolutional Neural Networks came to the conclusion that ResNet-101\cite{resnet} had the best accuracy among the rest of the networks and the papers with an really minimal clinical dataset with complete metadata. Nonetheless, the other papers, despite the fact of their decent accuracy, their datasets did not have complete metadata and they used online datasets from the internet. Except from the first paper\cite{firstreview}, the third one \cite{thirdreview}, had a high accuracy with an even more minimal dataset than the first one.\cite{firstreview} It was quite interesting because its method was a bit different than the others. 	Specifically, it extracted features from multiple Convolutional Neural Networks and used a Bayesnet classifier while the others used only exclusively pre-trained networks or transfer learning. Finally, our custom network, CovNet-101, and the second paper's network\cite{secondreview}, DarkCovidNet, had very close accuracy to the previous ones but their datasets had a bigger ammount of images.

\begin{table}[H]
  \begin{center}
    \caption{Results}
    \label{tab:table1}
    \begin{tabular}{||c c c c c c ||}
      \hline 
      \textbf{Reference} & \textbf{Problem} & \textbf{Method} & \textbf{Types of data} & \textbf{Sample size} & \textbf{Accuracy}\\ 
      \hline
      \cite{firstreview} & Binary Classification & ResNet-101 & Clinical & 108 patients & 99.51  \\ % <--
      \hline
      \cite{secondreview} & Binary Classification & DarkCovidNet & Online Datasets & 1127 images & 98.08 \\ % <--
      \hline
      \cite{thirdreview} & Binary Classification & Multi-CNN and Bayesnet & Online Datasets & 78 images & 97.44 \\ % <--
      \hline
      Custom & Binary Classification & COVnet-101 & Online Datasets & 6432 images & 97.40 \\ % <--
      \hline
    \end{tabular}
  \end{center}
\end{table}

\section{Future Work}
In the future we would like to focus mainly on the networks’ optimization. We would like to increase their accuracy and make them run faster. Another option would be the creation of an informative system. The informative system could contain a mobile app which could scan Chest x-rays  and could classify them as either COVID-19 positive or COVID-19 negative in the case that the CovidvsNonCovid network was used or could classify them as  COVID-19 positive or pneumonia positive or as healthy  in the case that the CovidvsHealthyvsPneumonia networkwas used and send them to a cloud server with their appropriate information (Disease, Patient ID, Age, Gender). The new X-rays could help the continuous training of the COVnet-101and make it more accurate. At the end of the day a huge dataset could be created in order to help more scientists create their custom networks.
 

\begin{thebibliography}{9}
\bibitem{firstcases} 
Zhu, Na, et al. 
\textit{A novel coronavirus from patients with pneumonia in China, 2019.}. 
New England Journal of Medicine (2020).

\bibitem{symptoms1}
Li, Long‐quan, et al.
\textit{COVID‐19 patients' clinical characteristics, discharge rate, and fatality rate of meta‐analysis.}
Journal of medical virology 92.6 (2020): 577-583.

\bibitem{symptoms2} 
Huang, Chaolin, et al. 
\textit{Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China.}.
The lancet 395.10223 (2020): 497-506.

\bibitem{patients}
Li, Bo, et al. 
\textit {Prevalence and impact of cardiovascular metabolic diseases on COVID-19 in China.} 
Clinical Research in Cardiology 109.5 (2020): 531-538.

\bibitem{medicalCOVID}
Abdulamir, Ahmed S., and Rand R. Hafidh.
\textit{The Possible Immunological Pathways for the Variable Immunopathogenesis of COVID--19 Infections among Healthy Adults, Elderly and Children.}
Electronic Journal of General Medicine 17.4 (2020).

\bibitem{firstreview}
Ardakani, Ali Abbasian, et al. 
\textit{Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks.}.
Computers in Biology and Medicine (2020): 103795.

\bibitem{alexnet}
Krizhevsky Ilya Sutskever, et al. 
\textit{Imagenet classification with deep convolutional neural networks.}. Advances in neural information processing systems. 2012.

\bibitem{vgg}
Simonyan, Karen, et al. 
\textit {Very deep convolutional networks for large-scale image recognition.}. arXiv preprint arXiv:1409.1556 (2014).

\bibitem{squeezenet}
Iandola, Forrest N., et al. 
\textit {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size.}. 
arXiv preprint arXiv:1602.07360 (2016).

\bibitem{googlenet}
C. Szegedy et al. 
\textit{Going deeper with convolutions}
2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, 2015, pp. 1-9, doi: 10.1109/CVPR.2015.7298594.

\bibitem{mobilenet}
M. Sandler, A. Howard et al. 
\textit{MobileNetV2: Inverted Residuals and Linear Bottlenecks}
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, 2018, pp. 4510-4520, doi: 10.1109/CVPR.2018.00474.

\bibitem{resnet}
K. He, X. Zhang, et al. 
\textit{Deep Residual Learning for Image Recognition.}. 
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, 2016, pp. 770-778, doi: 10.1109/CVPR.2016.90.

\bibitem{xception}
Chollet, François. 
\textit{Xception: Deep learning with depthwise separable convolutions.}. Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.

\bibitem{secondreview}
Ozturk, Tulin, et al. 
\textit{Automated detection of COVID-19 cases using deep neural networks with X-ray images}. 
Computers in Biology and Medicine (2020): 103792.

\bibitem{darknet}
Redmon, Joseph et al.
\textit{YOLO9000: better, faster, stronger.}.
Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.

\bibitem{dataset1secondreview}
J.P. Cohen
\textit{COVID-19 Image Data Collection. 2020.}
https://github.com/ieee8023/COVID-chestxray-dataset.

\bibitem{dataset2secondreview}
X. Wang et al. 
\textit{Chestx-ray8: hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases}
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2097–2106.

\bibitem{thirdreview}
Abraham, Bejoy et al. 
\textit{Computer-aided detection of COVID-19 from X-ray images using multi-CNN and Bayesnet classifier.}.
Biocybernetics and biomedical engineering 40.4 (2020): 1436-1445.

\bibitem{dataset1.2thirdreview}
Kermany, et al.
\textit{Identifying medical diagnoses and treatable diseases by image-based deep learning.}.
Cell 172.5 (2018): 1122-1131.

\bibitem{dataset2thirdreview}
Dadario AMV. Covid-19 X rays; 2020.
\textit{http://dx.doi.org/10.34740/KAGGLE/DSV/101946}. 
Available from:https://www.kaggle.com/dsv/1019469. 

\bibitem{imagenet}
Deng J et al.
\textit{Imagenet: alarge-scale hierarchical image database.}.
2009 IEEEConference on Computer Vision and Pattern Recognition.IEEE; 2009. p. 248–55.

\bibitem{shufflenet}
Zhang X et al.
\textit{Shufflenet: an extremelyefficient convolutional neural network for mobile devices.}.
Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition; 2018. p. 6848–56.

\bibitem{darknetpaper3}
Redmon J et al. 
\textit{Yolov3: an incremental improvement.}.
2018, arXiv preprint arXiv:1804.02767

\bibitem{dataset1custom}
Paul Mooney. Chest X-Ray Images (Pneumonia); 2017
\textit{Kaggle.}.
Available from: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia. 

\bibitem{datasetcustomcovid}
Wang et al.
\textit{COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images}
2020, https://doi.org/10.1038/s41598-020-76550-z

\bibitem{batchnormalization}
S. Ioffe and C. Szegedy. 
\textit{Batch normalization: Accelerating deep
network training by reducing internal covariate shift.}.
In ICML, 2015.

\bibitem{dropout}
G. E. Hinton et al. 
\textit{Improving neural networks by preventing co-
adaptation of feature detectors.}.
arXiv:1207.0580, 2012.

\end{thebibliography}
\end{document}
